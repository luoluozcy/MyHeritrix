# $Id: robots.txt,v 1.1 2009/05/21 12:00:00 $
#
# This is a file retrieved by webwalkers a.k.a. spiders that 
# conform to a defacto standard.
# See <URL:http://www.robotstxt.org/wc/exclusion.html#robotstxt>
#
# Format is:
#       User-agent: <name of spider>
#       Disallow: <nothing> | <path>
# -----------------------------------------------------------------------------

User-Agent: *
Sitemap: http://page.renren.com/sitemap.xml
Allow: /
Disallow: /6*/group*
Disallow: /6*/channel-forum*